{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "df_train=pd.read_csv(\"/Users/nabilch/Downloads/titanic/train.csv\")\n",
    "df_test=pd.read_csv(\"/Users/nabilch/Downloads/titanic/test.csv\")\n",
    "df_all=pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check and fix missing values and data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_train=pd.isnull(df_train).sum()\n",
    "missing_data_test=pd.isnull(df_test).sum()\n",
    "summary_train=df_train.describe()\n",
    "summary_test=df_test.describe()\n",
    "median_fare=np.nanmedian(df_all['Fare'])\n",
    "df_test[\"Fare\"]=df_test[\"Fare\"].fillna(median_fare)\n",
    "df_all['Title']=df_all.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "df_train['Title']=df_train.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "df_test['Title']=df_test.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "all_titles=(np.unique(df_all['Title'], return_counts=True))\n",
    "titles=[\"Master\", \"Miss\", \"Mr\", \"Mrs\"]\n",
    "df_all.loc[(~df_all['Title'].isin(titles)), 'Title'] = \"Other\"\n",
    "titledummies=pd.get_dummies(df_all[['Title']], prefix_sep='_', dtype=int)\n",
    "df_all=pd.concat([df_all, titledummies], axis=1)\n",
    "df_test.loc[(~df_test['Title'].isin(titles)), 'Title'] = \"Other\"\n",
    "titledummies=pd.get_dummies(df_test[['Title']], prefix_sep='_', dtype=int)\n",
    "df_test=pd.concat([df_test, titledummies], axis=1)\n",
    "df_train.loc[(~df_train['Title'].isin(titles)), 'Title'] = \"Other\"\n",
    "titledummies=pd.get_dummies(df_train[['Title']], prefix_sep='_', dtype=int)\n",
    "df_train=pd.concat([df_train, titledummies], axis=1)\n",
    "\n",
    "title_age = df_all.groupby('Title')['Age'].median()\n",
    "titles=[\"Master\", \"Miss\", \"Mr\", \"Mrs\", \"Other\"]\n",
    "for title in titles:\n",
    "    df_all.loc[(df_all['Age'].isnull()) & (df_all['Title'] == title), 'Age'] = title_age[title]\n",
    "    df_train.loc[(df_train['Age'].isnull()) & (df_train['Title'] == title), 'Age'] = title_age[title]\n",
    "    df_test.loc[(df_test['Age'].isnull()) & (df_test['Title'] == title), 'Age'] = title_age[title]\n",
    "df_train['Age_group'] = pd.cut(df_train['Age'], bins=[0,10,20,40,120], labels=['Children','Teenage','Adult','Elder'])\n",
    "df_test['Age_group'] = pd.cut(df_test['Age'], bins=[0,10,20,40,120], labels=['Children','Teenage','Adult','Elder'])\n",
    "df_all['Age_group'] = pd.cut(df_all['Age'], bins=[0,10,20,40,120], labels=['Children','Teenage','Adult','Elder'])\n",
    "df_train['Fare_bin'] = pd.cut(df_train['Fare'], bins=[0,7.91,14.45,31,120], labels=['Low_fare','median_fare','Average_fare','high_fare'])\n",
    "df_test['Fare_bin'] = pd.cut(df_test['Fare'], bins=[0,7.91,14.45,31,120], labels=['Low_fare','median_fare','Average_fare','high_fare'])\n",
    "df_all['Fare_bin'] = pd.cut(df_all['Fare'], bins=[0,7.91,14.45,31,120], labels=['Low_fare','median_fare','Average_fare','high_fare'])\n",
    "df_all['Embarked']=df_all['Embarked'].fillna('S')\n",
    "df_test['Embarked']=df_test['Embarked'].fillna('S')\n",
    "df_train['Embarked']=df_train['Embarked'].fillna('S')\n",
    "df_train = pd.get_dummies(df_train, columns = [\"Sex\", 'Pclass', \"Embarked\", \"Age_group\", 'Fare_bin'], prefix_sep=\"_\", dtype=int)\n",
    "df_test = pd.get_dummies(df_test, columns = [\"Sex\", 'Pclass', \"Embarked\", \"Age_group\", 'Fare_bin'], prefix_sep=\"_\", dtype=int)\n",
    "df_all['family']=df_all['SibSp']+df_all['Parch']+1\n",
    "df_train['family']=df_train['SibSp']+df_train['Parch']+1\n",
    "df_test['family']=df_test['SibSp']+df_test['Parch']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.drop(['Age', 'Fare', 'Title', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis= 1)\n",
    "df_test=df_test.drop(['Age', 'Fare', 'Title', 'Name', 'Ticket', 'Cabin'], axis= 1)\n",
    "predictors=df_train.drop(['Survived'], axis= 1)\n",
    "target=df_train['Survived']\n",
    "X_train, X_val, y_train, y_val=train_test_split(predictors, target, test_size=.2, random_state=10)\n",
    "kfold=KFold(n_splits=10,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic accuracy train:  0.8202247191011236\n",
      "Logistic accuracy validation:  0.8547486033519553\n",
      "Logistic accuracy cross-validation:  0.8192883895131086\n"
     ]
    }
   ],
   "source": [
    "log_reg_model=LogisticRegression()\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "print('Logistic accuracy train: ', log_reg_model.score(X_train, y_train))\n",
    "print('Logistic accuracy validation: ', accuracy_score(y_val, log_reg_model.predict(X_val)))\n",
    "cv_result = cross_val_score(log_reg_model,predictors,target, cv = kfold, scoring = \"accuracy\")\n",
    "print('Logistic accuracy cross-validation: ', cv_result.mean())\n",
    "log_reg_model.fit(predictors, target)\n",
    "df_test_predictors=df_test.drop(['PassengerId'], axis= 1)\n",
    "predictions=log_reg_model.predict(df_test_predictors)\n",
    "df_submission=pd.DataFrame({'PassengerID': df_test['PassengerId'], 'Survived': predictions})\n",
    "df_submission.to_csv('log_reg_titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy train:  0.8623595505617978\n",
      "Random forest accuracy validation:  0.8268156424581006\n",
      "Random forest accuracy cross-validation:  0.8192883895131086\n"
     ]
    }
   ],
   "source": [
    "rand_forest_model = RandomForestClassifier(n_estimators=20, max_depth=7)\n",
    "rand_forest_model.fit(X_train,y_train)\n",
    "print('Random forest accuracy train: ', rand_forest_model.score(X_train, y_train))\n",
    "print('Random forest accuracy validation: ', accuracy_score(y_val, rand_forest_model.predict(X_val)))\n",
    "cv_result = cross_val_score(rand_forest_model, predictors,target, cv = kfold, scoring = \"accuracy\")\n",
    "print('Random forest accuracy cross-validation: ', cv_result.mean())\n",
    "rand_forest_model.fit(predictors, target)\n",
    "predictions=rand_forest_model.predict(df_test_predictors)\n",
    "df_submission=pd.DataFrame({'PassengerID': df_test['PassengerId'], 'Survived': predictions})\n",
    "df_submission.to_csv('rand_forest_titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy train:  0.8497191011235955\n",
      "XGBoost accuracy validation:  0.8268156424581006\n",
      "XGBoost accuracy cross-validation:  0.8215480649188514\n"
     ]
    }
   ],
   "source": [
    "grad_boost_model = GradientBoostingClassifier(n_estimators=20,max_depth=4)\n",
    "grad_boost_model.fit(X_train,y_train)\n",
    "print('XGBoost accuracy train: ', grad_boost_model.score(X_train, y_train))\n",
    "print('XGBoost accuracy validation: ', accuracy_score(y_val, grad_boost_model.predict(X_val)))\n",
    "cv_result = cross_val_score(grad_boost_model, predictors,target, cv = kfold, scoring = \"accuracy\")\n",
    "print('XGBoost accuracy cross-validation: ', cv_result.mean())\n",
    "grad_boost_model.fit(predictors, target)\n",
    "predictions=grad_boost_model.predict(df_test_predictors)\n",
    "df_submission=pd.DataFrame({'PassengerID': df_test['PassengerId'], 'Survived': predictions})\n",
    "df_submission.to_csv('grad_boost_titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
